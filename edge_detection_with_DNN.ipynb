{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581d111f-6e97-471b-b8f7-907892cb24c7",
   "metadata": {},
   "source": [
    "## Edge Detection Based on Deep Neural Networks\n",
    "- detecting edges and object boundaries in natural images is a long-standing vision problem\n",
    "- edge detection, aims to extract visually salient edges and object boundaries, a low-level vision task\n",
    "- edges and boundaries are often considered to be semantically meaningful, but it is difficult to represent object-level information\n",
    "\n",
    "- methods of different types\n",
    "  - Early pioneering methods, extract local cues of low-level cues\n",
    "    - brightness, colors, textures, gradients\n",
    "    - methods, sobel detector, zero-crossing, Canny\n",
    "  - Learning based methods using hand-crafted features: mannuly design feature extractors using low-level cues, then employ learning paradigm to classify edge and non-edge pixels\n",
    "    - for example, Statistical Edges, Pb, gPb, sketch tokens\n",
    "  - structured edges （SE， high performance and speed）???\n",
    "  - Use DNN to extract hierarchical features/representations,\n",
    "    - methods, N4-fields, deep contour, deepedge, CSCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe27466-e133-4064-93b3-b9f0e2ddd48e",
   "metadata": {},
   "source": [
    "### Holistically-nested edge detection (HED)\n",
    "- ICCV 2015 / IJCV, Saining Xie, Zhuowen Tu, (UCSD)\n",
    "\n",
    "- solved two issues\n",
    "  - holistic image training and prediction (this is where holistically come from, imaged-to-image fashion)\n",
    "  - multi-scale and mutli-level feature learning (this is where nested come from, deep layer supervision to guide early classification results)\n",
    "- HED structure\n",
    "  - inspired by fully convolutional neural networks (FCN), and deeply-supervised nets (DSN).\n",
    "  - based on VGG Net, connect side output layer to the last convolutional layer in each stage, conv12, conv22, conv33, conv43, conv53\n",
    "  - pretrained on imagenet, supervised on each side output layer, \n",
    "  - deep supervision\n",
    "\n",
    "![HED network architecture](https://github.com/wasaCheney/edge_detection/blob/master/HED_architecture.png)\n",
    "\n",
    "\n",
    "- dataset\n",
    "  - Berkeley Segmentation Dataset and Benchmark, BSDS500\n",
    "  - NYU Depth Dataset, NYUD, 1449 RGB-D images, 381 training, 414 validation, and 654 testing\n",
    "    - Depth is embeded into three channels, HHA. Run two models on RGB and HHA separately, then average the results.\n",
    "- Performance Measurement\n",
    "  - fixed contour threshold, ODS\n",
    "  - per-image best threshold, OIS\n",
    "  - average precision, AP\n",
    "  - F-score\n",
    "  - frames per seconds, FPS\n",
    "\n",
    "- Misc\n",
    "  - deeply-supervised nets, integrates direct supervision to the hidden layers rather than the standard approach of providing supervision only at the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add453f0-cdef-4be5-b550-5f4cfd94a662",
   "metadata": {},
   "source": [
    "### Richer Convolutional Features for Edge Detection (RCF)\n",
    "- CVPR 2017/TPAMI, Yun Liu, Mingming Cheng, Nankai University, HUST\n",
    "- Difference from HED:\n",
    "  - Take all conv layers into consideration, to caputre more object or object part boundaries across a larger range of scales\n",
    "  - A novel loss, ignore edge pixels marked by a few annotators because of their confusing attributes\n",
    "  - Use image pyramids, then average results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f021bca-0b6b-481c-be3f-43d20d8bb0b4",
   "metadata": {},
   "source": [
    "### Unsupervised learning of edges\n",
    "- CVPR 2016, Y Li, based on HED but bad results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
